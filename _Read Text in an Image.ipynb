{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f34d986",
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_key = ''\n",
    "cog_endpoint = ''\n",
    "\n",
    "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38583707",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure.cognitiveservices.vision.computervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964b622b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Get a client for the computer vision service\n",
    "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
    "\n",
    "# Read the image file\n",
    "image_path = os.path.join('data', 'ocr', 'advert.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Use the Computer Vision service to find text in the image\n",
    "read_results = computervision_client.recognize_printed_text_in_stream(image_stream)\n",
    "\n",
    "# Process the text line by line\n",
    "for region in read_results.regions:\n",
    "    for line in region.lines:\n",
    "\n",
    "        # Read the words in the line of text\n",
    "        line_text = ''\n",
    "        for word in line.words:\n",
    "            line_text += word.text + ' '\n",
    "        print(line_text.rstrip())\n",
    "\n",
    "# Open image to display it.\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "img = Image.open(image_path)\n",
    "draw = ImageDraw.Draw(img)\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684f48c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open image to display it.\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "img = Image.open(image_path)\n",
    "draw = ImageDraw.Draw(img)\n",
    "\n",
    "# Process the text line by line\n",
    "for region in read_results.regions:\n",
    "    for line in region.lines:\n",
    "\n",
    "        # Show the position of the line of text\n",
    "        l,t,w,h = list(map(int, line.bounding_box.split(',')))\n",
    "        draw.rectangle(((l,t), (l+w, t+h)), outline='magenta', width=5)\n",
    "\n",
    "        # Read the words in the line of text\n",
    "        line_text = ''\n",
    "        for word in line.words:\n",
    "            line_text += word.text + ' '\n",
    "        print(line_text.rstrip())\n",
    "\n",
    "# Show the image with the text locations highlighted\n",
    "plt.axis('off')\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb21373c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.computervision import ComputerVisionClient\n",
    "from azure.cognitiveservices.vision.computervision.models import OperationStatusCodes\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import time\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Read the image file\n",
    "image_path = os.path.join('data', 'ocr', 'letter.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Get a client for the computer vision service\n",
    "computervision_client = ComputerVisionClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
    "\n",
    "# Submit a request to read printed text in the image and get the operation ID\n",
    "read_operation = computervision_client.read_in_stream(image_stream,\n",
    "                                                      raw=True)\n",
    "operation_location = read_operation.headers[\"Operation-Location\"]\n",
    "operation_id = operation_location.split(\"/\")[-1]\n",
    "\n",
    "# Wait for the asynchronous operation to complete\n",
    "while True:\n",
    "    read_results = computervision_client.get_read_result(operation_id)\n",
    "    if read_results.status not in [OperationStatusCodes.running]:\n",
    "        break\n",
    "    time.sleep(1)\n",
    "\n",
    "# If the operation was successfuly, process the text line by line\n",
    "if read_results.status == OperationStatusCodes.succeeded:\n",
    "    for result in read_results.analyze_result.read_results:\n",
    "        for line in result.lines:\n",
    "            print(line.text)\n",
    "\n",
    "# Open image and display it.\n",
    "print('\\n')\n",
    "fig = plt.figure(figsize=(12,12))\n",
    "img = Image.open(image_path)\n",
    "plt.axis('off')\n",
    "plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedabbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
