{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2971f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cog_key = ''\n",
    "cog_endpoint = ''\n",
    "\n",
    "print('Ready to use cognitive services at {} using key {}'.format(cog_endpoint, cog_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e9c9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_faces(image_path, detected_faces, show_id=False):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image, ImageDraw\n",
    "\n",
    "    # Open an image\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Create a figure to display the results\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "    if detected_faces:\n",
    "        # If there are faces, how many?\n",
    "        num_faces = len(detected_faces)\n",
    "        prediction = ' (' + str(num_faces) + ' faces detected)'\n",
    "        # Draw a rectangle around each detected face\n",
    "        for face in detected_faces:\n",
    "            r = face.face_rectangle\n",
    "            bounding_box = ((r.left, r.top), (r.left + r.width, r.top + r.height))\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            draw.rectangle(bounding_box, outline='magenta', width=5)\n",
    "            if show_id:\n",
    "                plt.annotate(face.face_id,(r.left, r.top + r.height + 15), backgroundcolor='white')\n",
    "        #a = fig.add_subplot(1,1,1)\n",
    "        fig.suptitle(prediction)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "\n",
    "def show_face_attributes(image_path, detected_faces):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image, ImageDraw\n",
    "\n",
    "    # Open an image\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Create a figure to display the results\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "    if detected_faces:\n",
    "        # If there are faces, how many?\n",
    "        num_faces = len(detected_faces)\n",
    "        prediction = ' (' + str(num_faces) + ' faces detected)'\n",
    "        # Draw a rectangle around each detected face\n",
    "        for face in detected_faces:\n",
    "            r = face.face_rectangle\n",
    "            bounding_box = ((r.left, r.top), (r.left + r.width, r.top + r.height))\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            draw.rectangle(bounding_box, outline='magenta', width=5)\n",
    "\n",
    "            # Annotate with face attributes (only age and emotion are used in this sample)\n",
    "            detected_attributes = face.face_attributes.as_dict()\n",
    "            age = 'age unknown' if 'age' not in detected_attributes.keys() else int(detected_attributes['age'])\n",
    "            annotations = 'Person aged approximately {}'.format(age)\n",
    "            txt_lines = 1\n",
    "            if 'emotion' in detected_attributes.keys():\n",
    "                for emotion_name in detected_attributes['emotion']:\n",
    "                    txt_lines += 1\n",
    "                    annotations += '\\n - {}: {}'.format(emotion_name, detected_attributes['emotion'][emotion_name])\n",
    "            plt.annotate(annotations,((r.left + r.width), (r.top + r.height + (txt_lines * 12))), backgroundcolor='white')\n",
    "\n",
    "        # Plot the image\n",
    "        #a = fig.add_subplot(1,1,1)\n",
    "        fig.suptitle(prediction)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "\n",
    "def show_similar_faces(image_1_path, image_1_face, image_2_path, image_2_faces, similar_faces):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image, ImageDraw\n",
    "\n",
    "    # Create a figure to display the results\n",
    "    fig = plt.figure(figsize=(16, 6))\n",
    "\n",
    "    # Show face 1\n",
    "    img1 = Image.open(image_1_path)\n",
    "    r = image_1_face.face_rectangle\n",
    "    bounding_box = ((r.left, r.top), (r.left + r.width, r.top + r.height))\n",
    "    draw = ImageDraw.Draw(img1)\n",
    "    draw.rectangle(bounding_box, outline='magenta', width=5)\n",
    "    a = fig.add_subplot(1,2,1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img1)\n",
    "\n",
    "    # get the matching face IDs\n",
    "    matching_face_ids = list(map(lambda face: face.face_id, similar_faces))\n",
    "\n",
    "    # Draw a rectangle around each similar face in image 2\n",
    "    img2 = Image.open(image_2_path)\n",
    "    a = fig.add_subplot(1,2,2)\n",
    "    plt.axis('off')\n",
    "    for face in image_2_faces:\n",
    "        r = face.face_rectangle\n",
    "        bounding_box = ((r.left, r.top), (r.left + r.width, r.top + r.height))\n",
    "        draw = ImageDraw.Draw(img2)\n",
    "        if face.face_id in matching_face_ids:\n",
    "            draw.rectangle(bounding_box, outline='lightgreen', width=10)\n",
    "            plt.annotate('Match!',(r.left, r.top + r.height + 15), backgroundcolor='white')\n",
    "        else:\n",
    "            draw.rectangle(bounding_box, outline='red', width=5)\n",
    "    plt.imshow(img2)\n",
    "    plt.show()\n",
    "\n",
    "def show_recognized_faces(image_path, detected_faces, recognized_face_names):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image, ImageDraw\n",
    "\n",
    "    # Open an image\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Create a figure to display the results\n",
    "    fig = plt.figure(figsize=(8, 6))\n",
    "\n",
    "    if detected_faces:\n",
    "        # If there are faces, how many?\n",
    "        num_faces = len(recognized_face_names)\n",
    "        caption = ' (' + str(num_faces) + ' faces recognized)'\n",
    "        # Draw a rectangle around each detected face\n",
    "        for face in detected_faces:\n",
    "            r = face.face_rectangle\n",
    "            bounding_box = ((r.left, r.top), (r.left + r.width, r.top + r.height))\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            draw.rectangle(bounding_box, outline='magenta', width=5)\n",
    "            if face.face_id in recognized_face_names:\n",
    "                plt.annotate(recognized_face_names[face.face_id],\n",
    "                             (r.left, r.top + r.height + 15), backgroundcolor='white')\n",
    "        #a = fig.add_subplot(1,1,1)\n",
    "        fig.suptitle(caption)\n",
    "\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ab4d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install azure.cognitiveservices.vision.face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af5b95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "# Create a face detection client.\n",
    "face_client = FaceClient(cog_endpoint, CognitiveServicesCredentials(cog_key))\n",
    "\n",
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "\n",
    "# Display the faces (code in python_code/faces.py)\n",
    "show_faces(image_path, detected_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd09cdd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream)\n",
    "\n",
    "# Display the faces (code in python_code/faces.py)\n",
    "show_faces(image_path, detected_faces, show_id=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4f032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open an image\n",
    "image_path = os.path.join('data', 'face', 'store_cam1.jpg')\n",
    "image_stream = open(image_path, \"rb\")\n",
    "\n",
    "# Detect faces and specified facial attributes\n",
    "attributes = ['age', 'emotion']\n",
    "detected_faces = face_client.face.detect_with_stream(image=image_stream, return_face_attributes=attributes)\n",
    "\n",
    "# Display the faces and attributes (code in python_code/faces.py)\n",
    "show_face_attributes(image_path, detected_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cc5702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the ID of the first face in image 1\n",
    "image_1_path = os.path.join('data', 'face', 'store_cam3.jpg')\n",
    "image_1_stream = open(image_1_path, \"rb\")\n",
    "image_1_faces = face_client.face.detect_with_stream(image=image_1_stream)\n",
    "face_1 = image_1_faces[0]\n",
    "\n",
    "# Get the face IDs in a second image\n",
    "image_2_path = os.path.join('data', 'face', 'store_cam2.jpg')\n",
    "image_2_stream = open(image_2_path, \"rb\")\n",
    "image_2_faces = face_client.face.detect_with_stream(image=image_2_stream)\n",
    "image_2_face_ids = list(map(lambda face: face.face_id, image_2_faces))\n",
    "\n",
    "# Find faces in image 2 that are similar to the one in image 1\n",
    "similar_faces = face_client.face.find_similar(face_id=face_1.face_id, face_ids=image_2_face_ids)\n",
    "\n",
    "# Show the face in image 1, and similar faces in image 2(code in python_code/face.py)\n",
    "show_similar_faces(image_1_path, face_1, image_2_path, image_2_faces, similar_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e10006",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8 - AzureML",
   "language": "python",
   "name": "python38-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
